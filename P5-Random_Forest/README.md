# Freq ML Project 5 - Random Forest (with XGBoost)
This is the fifth project for Cooper Union's Frequentist Machine Learning course.
It uses the SciKit Random Forest to predict Mashabnle news article popularity, source linked below.

Dataset used: https://archive.ics.uci.edu/ml/datasets/online+news+popularity#

## Assignment Description
#### Assignment 4: xTreme Gradient Boosted Trees
Read sections 15.1 - 15.3.
Select a dataset and perform a classification or regression on the dataset using the random forest algorithm in sci-kit learn.
Plot the feature importance.

## Notes
The random forest model significantly underperforms the baseline regressor (mean-based) on this dataset, while
performing pretty well on the randomly generated dummy dataset (dd) of similar dimensions.

The underperformance of the model on the real data can likely be attributed to the particular characteristics of the data used:
    
    1. The target distribution is highly imbalanced (exponentially decaying)
    
    2. As a result of the exponentially decaying nature of the distribution, there are a number of extreme outliers at the high end ( maximum > 240 x average )

These characteristics of the data are demonstrated by the images generated by the program.

There are three potential ways of addressing the above issues and improving the performance of the random forest model on this data:
    
    1. Logarithmically scaling or otherwise manipulating the output values to create a more level distribution for training
    
    2. Eliminating outliers from the dataset which would improve results but sacrifice a potentially crucial part of the data, the most popular news content
    
    3. Bin the data according to your predictive goals, and turn it into a classification problem (e.g. - predicting whether content will go viral)
